
# app.py â€” Unified Streamlit (EN + AR), PDF/TXT/DOCX, Batch CSV, Styled UI

import os, io, re, json, time
import pandas as pd
import numpy as np
import streamlit as st
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import matplotlib.pyplot as plt

# ---------- optional readers ----------
try:
    from pypdf import PdfReader as PYPDFReader
    _HAS_PYPDF = True
except Exception:
    _HAS_PYPDF = False

try:
    import pdfplumber
    _HAS_PLP = True
except Exception:
    _HAS_PLP = False

try:
    from pdfminer.high_level import extract_text as pdfminer_extract
    _HAS_PDFMINER = True
except Exception:
    _HAS_PDFMINER = False

from docx import Document

# ==================== THEME / STYLE ====================
st.set_page_config(page_title="Resume Classifier Â· EN + AR", page_icon="ğŸ§ ", layout="wide")
PRIMARY = "#5B8DEF"
ACCENT  = "#22C55E"
DANGER  = "#EF4444"
BG      = "#0f172a"
CARD    = "#111827"
TEXT    = "#E5E7EB"

st.markdown(f"""
<style>
  .stApp {{
    background: radial-gradient(1200px circle at 10% 0%, {BG} 0%, #030712 55%);
    color: {TEXT};
  }}
  .glass {{
    background: linear-gradient(180deg, rgba(255,255,255,0.06), rgba(255,255,255,0.03));
    border: 1px solid rgba(255,255,255,0.08);
    border-radius: 18px;
    padding: 18px 20px;
    box-shadow: 0 20px 50px rgba(0,0,0,0.35);
  }}
  .pill {{ display:inline-block; padding:4px 10px; border-radius:999px; font-size:12px;
           border:1px solid rgba(255,255,255,.15); margin-right:6px; }}
  .primary {{ color:white; background:{PRIMARY}; border:none; }}
  .accent {{ color:black; background:{ACCENT}; border:none; }}
  h1, h2, h3, h4 {{ color: #F8FAFC; }}
  .small-muted {{ color:#94A3B8; font-size:13px; }}
  .rtl * {{ direction: rtl; text-align: right; }}
</style>
""", unsafe_allow_html=True)

# ==================== CONFIG ====================
EN_MODEL_DIR = st.secrets.get("EN_REPO", "llm_model_en")
AR_MODEL_DIR = st.secrets.get("AR_REPO", "llm_model_ar")
DEFAULT_TOPK = 5
DEFAULT_MAXLEN = 256
os.environ.setdefault("PYTORCH_MPS_HIGH_WATERMARK_RATIO", "0.0")


# ==================== HELPERS ====================
@st.cache_resource(show_spinner=True)
def load_artifacts(model_dir: str):
    tok = AutoTokenizer.from_pretrained(model_dir, use_fast=True)
    mdl = AutoModelForSequenceClassification.from_pretrained(model_dir)
    labels_path = os.path.join(model_dir, "labels.json")
    id2label = None
    if os.path.exists(labels_path):
        with open(labels_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        if isinstance(data, dict) and "labels" in data:
            labels = data["labels"]
            id2label = {i: str(lbl) for i, lbl in enumerate(labels)}
        elif isinstance(data, dict) and "id2label" in data:
            id2label = {int(k): str(v) for k, v in data["id2label"].items()}
        else:
            try:
                id2label = {int(k): str(v) for k, v in data.items()}
            except Exception:
                pass
    if id2label is None and hasattr(mdl.config, "id2label"):
        id2label = {int(k): str(v) for k, v in mdl.config.id2label.items()}
    if id2label is None:
        raise FileNotFoundError("labels.json not found or invalid, and no id2label in model config.")
    mdl.config.id2label = id2label
    mdl.config.label2id = {v: k for k, v in id2label.items()}
    mdl.eval()
    return tok, mdl, id2label

def pick_device():
    if torch.cuda.is_available(): return torch.device("cuda")
    if torch.backends.mps.is_available(): return torch.device("mps")
    return torch.device("cpu")

def read_txt(file) -> str:
    b = file.read()
    try:
        return b.decode("utf-8")
    except Exception:
        return b.decode("latin-1", errors="ignore")

def read_docx(file) -> str:
    bio = io.BytesIO(file.read())
    doc = Document(bio)
    return "\n".join([p.text for p in doc.paragraphs]).strip()

def pdf_text_english(file) -> str:
    try:
        from PyPDF2 import PdfReader
        reader = PdfReader(file)
        pages = []
        for p in reader.pages:
            try:
                pages.append(p.extract_text() or "")
            except Exception:
                pages.append("")
        return "\n".join(pages).strip()
    except Exception:
        return ""

def _pdf_text_with_pypdf(file) -> str:
    reader = PYPDFReader(file)
    pages = []
    for p in reader.pages:
        try:
            pages.append(p.extract_text() or "")
        except Exception:
            pages.append("")
    return "\n".join(pages)

def _pdf_text_with_pdfplumber(file) -> str:
    if hasattr(file, "read"):
        b = file.read()
        if hasattr(file, "seek"): file.seek(0)
    else:
        b = file
    txt_pages=[]
    with pdfplumber.open(io.BytesIO(b)) as pdf:
        for page in pdf.pages:
            t = page.extract_text() or ""
            txt_pages.append(t)
    out = "\n".join(txt_pages)
    return re.sub(r"\\s+", " ", out).strip()

def _pdf_text_with_pdfminer(file) -> str:
    if hasattr(file, "read"):
        b = file.read()
        bio = io.BytesIO(b)
        txt = pdfminer_extract(bio)
        if hasattr(file, "seek"): file.seek(0)
    else:
        txt = pdfminer_extract(file)
    return txt

def pdf_text_arabic(file) -> str:
    txt = ""
    try:
        if _HAS_PYPDF:
            txt = _pdf_text_with_pypdf(file)
    except Exception:
        txt = ""
    def bad(s: str) -> bool:
        s = (s or "").strip()
        return (len(s) < 120) or ("ï»¼" in s) or (s.count("\\u200f") > 50)
    if bad(txt) and _HAS_PLP:
        try:
            if hasattr(file, "seek"): file.seek(0)
            t2 = _pdf_text_with_pdfplumber(file)
            if len(t2) > len(txt): txt = t2
        except Exception:
            pass
    if bad(txt) and _HAS_PDFMINER:
        try:
            if hasattr(file, "seek"): file.seek(0)
            t3 = _pdf_text_with_pdfminer(file)
            if len(t3) > len(txt): txt = t3
        except Exception:
            pass
    return re.sub(r"\\s+", " ", txt or "").strip()

def load_file_text(uploaded, lang: str) -> str:
    name = uploaded.name.lower()
    if name.endswith(".pdf"):
        if hasattr(uploaded, "seek"): uploaded.seek(0)
        return pdf_text_arabic(uploaded) if lang=="Arabic" else pdf_text_english(uploaded)
    if name.endswith(".txt"):   return read_txt(uploaded)
    if name.endswith(".docx"):  return read_docx(uploaded)
    raise ValueError("Unsupported file type. Upload PDF / TXT / DOCX.")

def normalize_ar(text: str) -> str:
    _map = str.maketrans({"Ø£":"Ø§","Ø¥":"Ø§","Ø¢":"Ø§","Ù‰":"ÙŠ","Ø¤":"Ùˆ","Ø¦":"ÙŠ","Ø©":"Ù‡"})
    text = re.sub(r"[\\u0617-\\u061A\\u064B-\\u0652]", "", text or "")
    text = (text or "").translate(_map)
    text = re.sub(r"[^\\u0600-\\u06FF0-9a-zA-Z\\s%+@\\-\\.]", " ", text)
    text = re.sub(r"\\s+", " ", text).strip()
    return text

def predict_text(text: str, tok, mdl, id2label, device, max_len=DEFAULT_MAXLEN, top_k=DEFAULT_TOPK, lang="English"):
    txt = normalize_ar(text) if lang=="Arabic" else (text or "")
    enc = tok(txt, return_tensors="pt", truncation=True, padding=True, max_length=max_len)
    enc = {k: v.to(device) for k, v in enc.items()}
    with torch.no_grad():
        logits = mdl(**enc).logits
        probs = torch.softmax(logits, dim=-1).squeeze(0)
        k = min(top_k, probs.shape[-1])
        conf, idx = torch.topk(probs, k=k)
    items = [(id2label[i.item()], float(c)) for i, c in zip(idx, conf)]
    return items

def df_topk(items):
    return pd.DataFrame([{"label": lbl, "probability": round(p, 6)} for lbl, p in items])

def meter(value, label, color=PRIMARY):
    st.markdown(
        f"""<div class="glass" style="background:{CARD}; margin:6px 0;">
              <div style="display:flex; justify-content:space-between; align-items:center;">
                <div style="font-weight:600;">{label}</div>
                <div style="font-weight:700;">{value:.1f}%</div>
              </div>
              <div style="height:10px; background:#1f2937; border-radius:999px; overflow:hidden; margin-top:6px;">
                <div style="height:10px; width:{value}%; background:{color};"></div>
              </div>
            </div>""",
        unsafe_allow_html=True
    )

# ==================== HEADER ====================
st.markdown(
    f"""
<div class="glass" style="padding:24px; margin-bottom:14px;">
  <div style="display:flex; gap:16px; align-items:center; flex-wrap:wrap;">
    <div class="pill primary">LLM</div>
    <div class="pill">PDF</div>
    <div class="pill">TXT</div>
    <div class="pill">DOCX</div>
    <div class="pill accent">CSV Batch</div>
  </div>
  <h1 style="margin:6px 0 0 0;">ğŸ§  Resume Classifier â€” English & Arabic</h1>
  <div class="small-muted">Upload <b>PDF / TXT / DOCX</b> or paste text Â· batch CSV supported Â· language-aware pipeline</div>
  <div class="small-muted">By : Reema Balharith</div>
</div>
""",
    unsafe_allow_html=True
)

# ==================== SIDEBAR ====================
with st.sidebar:
    st.markdown("### âš™ï¸ Settings")
    lang = st.radio("Language / Ø§Ù„Ù„ØºØ©", ["English","Arabic"], horizontal=True)
    st.markdown('<div class="rtl"></div>' if lang=="Arabic" else "", unsafe_allow_html=True)

    # -------- Sticky Model IDs --------
    # Ù„Ùˆ Ù…Ø§ ÙÙŠÙ‡ Ù‚ÙŠÙ…Ø© Ù…Ø­ÙÙˆØ¸Ø©ØŒ Ù†Ø®Ù„ÙŠÙ‡Ø§ Ù…Ù† Secrets Ø£Ùˆ Ø§Ù„Ø¯ÙŠÙÙˆÙ„Øª
    if "en_repo" not in st.session_state:
        st.session_state["en_repo"] = EN_MODEL_DIR
    if "ar_repo" not in st.session_state:
        st.session_state["ar_repo"] = AR_MODEL_DIR

    # Ù†Ø±Ø¨Ø· text_input Ù…Ø¹ session_state Ù…Ø¨Ø§Ø´Ø±Ø©
    en_model_dir = st.text_input(
        "EN model (HF repo id)", 
        value=st.session_state["en_repo"], 
        key="en_repo"
    )
    ar_model_dir = st.text_input(
        "AR model (HF repo id)", 
        value=st.session_state["ar_repo"], 
        key="ar_repo"
    )

    max_len = st.slider("Max tokens", 64, 512, DEFAULT_MAXLEN, step=32)
    top_k   = st.slider("Top-k", 1, 10, DEFAULT_TOPK)
    device = torch.device("cpu")  # Ø³ØªØ±ÙŠÙ…Ù„Øª ÙƒÙ„Ø§ÙˆØ¯ = CPU
    st.success(f"Device: {device}")

# ==================== TABS ====================
t1, t2, t3 = st.tabs(["ğŸ”® Predict", "ğŸ“¦ Batch (CSV)", "ğŸ“Š EDA"])

# -------- PREDICT TAB --------
with t1:
    cols = st.columns([1,1])
    with cols[0]:
        st.subheader("Paste text" if lang=="English" else "Ù„ØµÙ‚ Ù†Øµ")
        placeholder = "Paste resume text hereâ€¦" if lang=="English" else "Ø§Ù„ØµÙ‚ÙŠ Ù†Øµ Ø§Ù„Ø³ÙŠØ±Ø© Ø§Ù„Ø°Ø§ØªÙŠØ© Ù‡Ù†Ø§â€¦"
        txt = st.text_area(placeholder, height=220)
        btn_txt = st.button("Predict from text" if lang=="English" else "ØªÙ†Ø¨Ø¤ Ù…Ù† Ø§Ù„Ù†Øµ",
                            type="primary", use_container_width=True)

    with cols[1]:
        st.subheader("Upload file (PDF / TXT / DOCX)" if lang=="English" else "Ø±ÙØ¹ Ù…Ù„Ù (PDF / TXT / DOCX)")
        file = st.file_uploader("Choose a file" if lang=="English" else "Ø§Ø®ØªØ§Ø±ÙŠ Ù…Ù„ÙÙ‹Ø§",
                                type=["pdf","txt","docx"], accept_multiple_files=False)
        btn_file = st.button("Predict from file" if lang=="English" else "ØªÙ†Ø¨Ø¤ Ù…Ù† Ø§Ù„Ù…Ù„Ù",
                             use_container_width=True)

    def run_predict(raw_text: str):
        if not raw_text.strip():
            st.warning("Please provide text or upload a file." if lang=="English" else "ÙØ¶Ù„Ø§Ù‹ Ø§Ø¯Ø®Ù„ÙŠ Ù†ØµÙ‹Ø§ Ø£Ùˆ Ø§Ø±ÙØ¹ÙŠ Ù…Ù„ÙÙ‹Ø§.")
            return
        with st.spinner("Running predictionâ€¦" if lang=="English" else "Ø¬Ø§Ø±Ù Ø§Ù„ØªÙ†Ø¨Ø¤â€¦"):
            items = predict_text(raw_text, tok, mdl, id2label, device, max_len=max_len, top_k=top_k, lang=lang)
        pred, conf = items[0]
        st.markdown(
            f"### âœ… Prediction: **{pred}**  Â·  Confidence: **{conf:.1%}**"
            if lang=="English" else
            f"### âœ… Ø§Ù„ÙØ¦Ø© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©: **{pred}**  Â·  Ø§Ù„ÙˆØ«ÙˆÙ‚ÙŠØ©: **{conf:.1%}**"
        )
        if show_bars:
            for i,(lbl,p) in enumerate(items):
                meter(p*100, lbl, color=ACCENT if i==0 else PRIMARY)
        st.markdown("#### Top-k probabilities" if lang=="English" else "#### Ø£ÙØ¶Ù„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (Top-k)")
        st.dataframe(df_topk(items), use_container_width=True)

    if btn_txt:
        run_predict(txt)
    if btn_file:
        if file is None:
            st.warning("Upload a file first." if lang=="English" else "ÙØ¶Ù„Ø§Ù‹ Ø§Ø®ØªØ§Ø±ÙŠ Ù…Ù„ÙÙ‹Ø§ Ø£ÙˆÙ„Ø§Ù‹.")
        else:
            try:
                raw_text = load_file_text(file, lang)
                st.caption(
                    f"Loaded {len(raw_text)} characters from **{file.name}**"
                    if lang=="English" else f"ØªÙ… ØªØ­Ù…ÙŠÙ„ **{file.name}** â€” Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø±Ù: {len(raw_text)}"
                )
                run_predict(raw_text)
            except Exception as e:
                st.error(f"Failed to read file: {e}" if lang=="English" else f"ØªØ¹Ø°Ù‘Ø± Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù: {e}")

# -------- BATCH TAB --------
with t2:
    st.subheader("Batch prediction from CSV" if lang=="English" else "ØªÙ†Ø¨Ø¤ Ø¯ÙØ¹ÙŠ Ù…Ù† CSV")
    st.caption(
        "CSV must contain a column named **text**."
        if lang=="English" else "ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ­ØªÙˆÙŠ CSV Ø¹Ù„Ù‰ Ø¹Ù…ÙˆØ¯ Ø§Ø³Ù…Ù‡ **text** (Ù†Øµ Ø§Ù„Ø³ÙŠØ±Ø©)."
    )
    csv = st.file_uploader("Upload CSV", type=["csv"], accept_multiple_files=False, key="csvup_any")
    if csv is not None:
        try:
            df = pd.read_csv(csv)
        except Exception as e:
            st.error(f"Failed to read CSV: {e}" if lang=="English" else f"ØªØ¹Ø°Ù‘Ø± Ù‚Ø±Ø§Ø¡Ø© CSV: {e}")
            st.stop()
        if "text" not in df.columns:
            st.error("CSV must include a column named `text`." if lang=="English" else "ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ­ØªÙˆÙŠ CSV Ø¹Ù„Ù‰ Ø¹Ù…ÙˆØ¯ Ø¨Ø§Ø³Ù… `text`.")
        else:
            df["text"] = df["text"].fillna("").astype(str)
            preds, topk_json = [], []
            prog = st.progress(0, text="Predictingâ€¦" if lang=="English" else "ØªØ´ØºÙŠÙ„ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øªâ€¦")
            t0 = time.time()
            for i, t in enumerate(df["text"].tolist(), start=1):
                items = predict_text(t,
                                     tok, mdl, id2label, device,
                                     max_len=max_len, top_k=top_k, lang=lang)
                preds.append(items[0][0])
                topk_json.append(json.dumps([{"label":l,"prob":float(p)} for l,p in items], ensure_ascii=False))
                prog.progress(i/len(df))
            dt = time.time() - t0

            out = df.copy()
            out["prediction"] = preds
            out["topk_probs"] = topk_json

            st.success(
                f"Done: {len(df)} rows Â· {dt:.1f}s"
                if lang=="English" else f"ØªÙ…: {len(df)} ØµÙÙ‹Ø§ Â· {dt:.1f}Ø«"
            )
            st.dataframe(out.head(25), use_container_width=True)

            st.download_button(
                "â¬‡ï¸ Download predictions" if lang=="English" else "â¬‡ï¸ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬",
                out.to_csv(index=False).encode("utf-8"),
                file_name=("predictions_en.csv" if lang=="English" else "predictions_ar.csv"),
                mime="text/csv",
                use_container_width=True
            )

# -------- EDA TAB --------
with t3:
    st.subheader("Quick EDA (by predictions)" if lang=="English" else "Ø§Ø³ØªÙƒØ´Ø§Ù Ø³Ø±ÙŠØ¹ (Ø­Ø³Ø¨ ØªÙ†Ø¨Ø¤Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬)")
    st.caption(
        "Paste or upload multiple resumes to see label distribution by model predictions."
        if lang=="English" else "Ø§Ø±ÙØ¹ÙŠ Ø¹Ø¯Ø© Ù…Ù„ÙØ§Øª Ø£Ùˆ Ø§Ù„ØµÙ‚ÙŠ Ù†ØµÙˆØµÙ‹Ø§ Ù…ÙØµÙˆÙ„Ø© Ø¨Ù€ --- Ù„Ø¹Ø±Ø¶ ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©."
    )
    files = st.file_uploader("Upload multiple files (PDF/TXT/DOCX)" if lang=="English" else "Ø§Ø±ÙØ¹ÙŠ Ø¹Ø¯Ø© Ù…Ù„ÙØ§Øª (PDF/TXT/DOCX)",
                             type=["pdf","txt","docx"], accept_multiple_files=True, key="edafiles_any")
    bulk_txt = st.text_area(
        "Or paste multiple resumes separated by ---" if lang=="English" else "Ø£Ùˆ Ø§Ù„ØµÙ‚ÙŠ Ø¹Ø¯Ø© Ø³ÙŠØ± Ù…ÙØµÙˆÙ„Ø© Ø¨Ù€ ---",
        height=160, key="edatxt_any"
    )
    go = st.button("Run EDA" if lang=="English" else "ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø³ØªÙƒØ´Ø§Ù", type="primary")

    if go:
        texts=[]
        if bulk_txt.strip():
            parts=[p.strip() for p in bulk_txt.split("---") if p.strip()]
            texts.extend(parts)
        for f in files or []:
            try:
                texts.append(load_file_text(f, lang))
            except Exception as e:
                st.warning(f"Skip {getattr(f,'name','file')}: {e}" if lang=="English" else f"ØªØ®Ø·ÙŠ {getattr(f,'name','file')}: {e}")

        if not texts:
            st.warning("Provide some resumes first (text or files)." if lang=="English" else "ÙØ¶Ù„Ø§Ù‹ Ø§Ø¯Ø®Ù„ÙŠ Ù†ØµÙˆØµÙ‹Ø§ Ø£Ùˆ Ø§Ø±ÙØ¹ÙŠ Ù…Ù„ÙØ§Øª Ø£ÙˆÙ„Ø§Ù‹.")
        else:
            labels_pred=[]
            for t in texts:
                items = predict_text(t, tok, mdl, id2label, device, max_len=DEFAULT_MAXLEN, top_k=DEFAULT_TOPK, lang=lang)
                labels_pred.append(items[0][0])

            dist = pd.Series(labels_pred).value_counts().sort_values(ascending=False)
            st.markdown("#### Distribution (by predicted label)" if lang=="English" else "#### ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©")
            fig, ax = plt.subplots(figsize=(8,4))
            color = "#38bdf8" if lang=="Arabic" else "#22c55e"
            dist.plot(kind="bar", ax=ax, color=color)
            ax.set_xlabel("Label" if lang=="English" else "Ø§Ù„ÙØ¦Ø©")
            ax.set_ylabel("Count" if lang=="English" else "Ø§Ù„Ø¹Ø¯Ø¯")
            ax.set_title("Predicted label counts" if lang=="English" else "ØªÙˆØ²ÙŠØ¹ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª")
            st.pyplot(fig, clear_figure=True)

            st.markdown("#### Table" if lang=="English" else "#### Ø¬Ø¯ÙˆÙ„")
            st.dataframe(
                dist.reset_index().rename(columns={"index":"label" if lang=="English" else "Ø§Ù„ÙØ¦Ø©", 0:"count" if lang=="English" else "Ø§Ù„Ø¹Ø¯Ø¯"}),
                use_container_width=True
            )

# ==================== FOOTER ====================
st.markdown(
    f"""
<div class="small-muted" style="margin-top:24px; text-align:center;">
  Models: <b>{EN_MODEL_DIR}</b> (EN) Â· <b>{AR_MODEL_DIR}</b> (AR). You can change these in the sidebar.<br/>
  Upload supports <b>PDF, TXT, DOCX</b> Â· Batch mode expects CSV column <code>text</code>.
</div>
""",
    unsafe_allow_html=True
)
